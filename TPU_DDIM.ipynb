{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU DDIM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNvXm6mAOJrbuppiHE2QAUV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halcy/tpuddim/blob/main/TPU_DDIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZsydUDmQuBT"
      },
      "source": [
        "# TPU DDIM Colab notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI8gUnVLwrlV",
        "outputId": "820773ba-88da-4f70-e372-cb12d535edb9"
      },
      "source": [
        "# Catchall \"what is this runtime\" cell\n",
        "!nvidia-smi\n",
        "GPU = !nvidia_smi\n",
        "\n",
        "if len(GPU) > 3:\n",
        "    GPU = True\n",
        "else:\n",
        "    GPU = False\n",
        "\n",
        "!vmstat\n",
        "print(\"\")\n",
        "\n",
        "import os\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ:\n",
        "    from tensorflow.python.profiler import profiler_client\n",
        "    print(\"tpu:\", os.environ['COLAB_TPU_ADDR'])\n",
        "    tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n",
        "    print(profiler_client.monitor(tpu_profile_service_address, 100, 2).strip())\n",
        "    TPU = True\n",
        "else:\n",
        "    print(\"tpu: no\")\n",
        "    TPU = False\n",
        "\n",
        "CPUS = os.cpu_count()\n",
        "print(\"\\ncpus:\", CPUS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n",
            " r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n",
            " 1  0      0 33493092 107240 2394784    0    0    53     2   26  325  0  0 100  0  0\n",
            "\n",
            "tpu: 10.14.51.178:8470\n",
            "Timestamp: 16:53:24\n",
            "  TPU type: TPU v2\n",
            "  Utilization of TPU Matrix Units (higher is better): 0.000%\n",
            "\n",
            "cpus: 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcWWDPaGQmTG"
      },
      "source": [
        "# Basic setup\n",
        "\n",
        "Set up TPU, import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmhGBH-7zUJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ad8de1-7905-44f3-e98b-6d7adb0bcfb8"
      },
      "source": [
        "# Set JAX, flax and optax up for the TPU\n",
        "!pip install --upgrade -q jax jaxlib optax tqdm\n",
        "!pip install --upgrade flax\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "if 'TPU_DRIVER_MODE' not in globals():\n",
        "    url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver_nightly'\n",
        "    resp = requests.post(url)\n",
        "    TPU_DRIVER_MODE = 1\n",
        "\n",
        "# TPU driver as backend for JAX\n",
        "from jax.config import config\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (from flax) (0.0.9)\n",
            "Requirement already satisfied: jax>=0.2.13 in /usr/local/lib/python3.7/dist-packages (from flax) (0.2.18)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.13->flax) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.13->flax) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.2.13->flax) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.3.1)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.1.69+cuda110)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.0.8)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.11.1)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax) (1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHfiPH6dvtTQ"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import jit, lax\n",
        "from jax import nn as jnn\n",
        "from jax import random as jr\n",
        "import functools\n",
        "\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from flax.core import freeze, unfreeze\n",
        "\n",
        "from typing import Any, Callable, Sequence, Optional\n",
        "\n",
        "from jax.experimental.maps import xmap, mesh\n",
        "from jax.experimental.pjit import pjit, PartitionSpec\n",
        "from jax.experimental import stax\n",
        "\n",
        "import optax\n",
        "import tqdm\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Pinky promise: We are now aware xmap is experimental, and will adjust our expectations accordingly\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"xmap is an experimental feature and probably has bugs!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbHUX9RfxFKs"
      },
      "source": [
        "# Generate PRNG state\n",
        "prng = jr.PRNGKey(23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgVg9FFcVCdV"
      },
      "source": [
        "# Blocks for a diffusion model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIZm0BEWBGrn"
      },
      "source": [
        "### Timestep embedding, block sequencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ4kbxHJA1zS"
      },
      "source": [
        "class TimeEmbed(nn.Module):\n",
        "    \"\"\"\n",
        "    Timestep embedding module\n",
        "    \"\"\"\n",
        "    time_embed_dim: int\n",
        "    max_period: int\n",
        "    project_embed_dim: int\n",
        "    embed_dtype: jnp.dtype = jnp.float32\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, timesteps):\n",
        "        # Calculate sinusodial embedding\n",
        "        half = self.time_embed_dim // 2\n",
        "        freqs = jnp.exp(-math.log(self.max_period) * jnp.arange(0, half) / half)\n",
        "        args = timesteps[:, None].astype(self.embed_dtype) * freqs[None]\n",
        "        embedding = jnp.concatenate([jnp.cos(args), jnp.sin(args)], axis = -1)\n",
        "        if self.time_embed_dim % 2:\n",
        "            embedding = jnp.concatenate([embedding, jnp.zeros(embedding[:, :1].shape)], axis = -1)\n",
        "\n",
        "        # Some dense layers to properly embed for real\n",
        "        embedding = nn.Dense(self.project_embed_dim)(embedding)\n",
        "        embedding = nn.silu(embedding)\n",
        "        embedding = nn.Dense(self.project_embed_dim)(embedding)\n",
        "        \n",
        "        return embedding\n",
        "\n",
        "class TimestepBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Interface for modules that can take timestep embeddings as input\n",
        "    in addition to regular embeddings.\n",
        "    \"\"\"\n",
        "    def __call__(self, x, emb):\n",
        "        pass\n",
        "\n",
        "class TimestepEmbedSequential(TimestepBlock):\n",
        "    \"\"\"\n",
        "    Block that passes timestep embeddings to all submodules that\n",
        "    want them.\n",
        "\n",
        "    Also works as a regular sequential type module\n",
        "    \"\"\"\n",
        "    layers: Sequence[nn.Module]\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, emb = None):\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, TimestepBlock):\n",
        "                x = layer(x, emb)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x\n",
        "\n",
        "class TimestepBlockTest(TimestepBlock):\n",
        "    \"\"\"\n",
        "    Dummy block for testing\n",
        "    \"\"\"\n",
        "    @nn.compact\n",
        "    def __call__(self, x, emb):\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d921MA1WglQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c806331f-4413-4083-fa90-b930022153c9"
      },
      "source": [
        "# Lets see if it works\n",
        "\"\"\"\n",
        "embed_test = TimeEmbed(16, 10000, 16 * 4)\n",
        "embed_in = jnp.zeros((10, 1))\n",
        "params = embed_test.init(prng, embed_in)\n",
        "embed_test.apply(params, embed_in).shape\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nembed_test = TimeEmbed(16, 10000, 16 * 4)\\nembed_in = jnp.zeros((10, 1))\\nparams = embed_test.init(prng, embed_in)\\nembed_test.apply(params, embed_in).shape\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuUrBmduBOuz"
      },
      "source": [
        "### Convolution, pooling and identity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDLtmReCBB2x"
      },
      "source": [
        "class ConvND(nn.Module):\n",
        "    \"\"\"\n",
        "    n-D convolution with square kernel\n",
        "    \"\"\"\n",
        "    dims: int\n",
        "    out_channels: int\n",
        "    kernel_size: int\n",
        "    stride: int = 1\n",
        "    padding: int = 'SAME'\n",
        "\n",
        "    def setup(self):\n",
        "        self.kernel = tuple([self.kernel_size] * self.dims)\n",
        "        self.strides = tuple([self.stride] * self.dims)\n",
        "        if self.padding in ['SAME', 'VALID']:\n",
        "            self.paddings = self.padding\n",
        "        else:\n",
        "            self.paddings = tuple([(self.padding, self.padding)] * self.dims)\n",
        "        self.conv = nn.Conv(self.out_channels, self.kernel, self.strides, self.paddings)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class AvgND(nn.Module):\n",
        "    \"\"\"\n",
        "    n-D average pooling with square window\n",
        "\n",
        "    Numeric padding is NOT supported, specify either SAME or VALID padding.\n",
        "    \"\"\"\n",
        "    dims: int\n",
        "    window_size: int = 2\n",
        "    stride: int = 2\n",
        "    padding: int = 'VALID'\n",
        "\n",
        "    def setup(self):\n",
        "        self.window = [1] + [self.window_size] * self.dims\n",
        "        self.strides = [1] + [self.stride] * self.dims\n",
        "        if self.padding in ['SAME', 'VALID']:\n",
        "            self.paddings = self.padding\n",
        "\n",
        "    def __call__(self, x):\n",
        "        full_window = tuple(list(self.window) + list([1] * (len(x.shape) - len(self.window) - 1)))\n",
        "        full_strides = tuple(list(self.strides) + list([1] * (len(x.shape) - len(self.window) - 1)))\n",
        "        return nn.avg_pool(x, full_window, full_strides, self.paddings)\n",
        "\n",
        "class Identity(nn.Module):\n",
        "  \"\"\"\n",
        "  For model building convenience, a class that does nothing\n",
        "  \"\"\"\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoqDGvWaBTs_"
      },
      "source": [
        "### Up- and Downsampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBo1s3I0AzIH"
      },
      "source": [
        "class Scale2X(nn.Module):\n",
        "  \"\"\"\n",
        "  nD 2x nearest neighbour scaling\n",
        "  \"\"\"\n",
        "  dims: int\n",
        "  \n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "      for i in range(1, self.dims + 1):\n",
        "          x = jnp.repeat(x, 2, axis = i)\n",
        "      return x\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    \"\"\"\n",
        "    Upsampling layer, factor 2\n",
        "\n",
        "    Nearest neighour (element repeating), optionally with a convolution afterwards.\n",
        "    \"\"\"\n",
        "    dims: int\n",
        "    out_channels: int = 0\n",
        "    use_conv: bool = False\n",
        "\n",
        "    def setup(self):\n",
        "        self.scale = Scale2X(self.dims)\n",
        "        if self.use_conv:\n",
        "            assert self.out_channels != 0\n",
        "            self.conv = ConvND(self.dims, self.out_channels, 3)\n",
        "        else:\n",
        "            self.conv = Identity()\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.scale(x)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    \"\"\"\n",
        "    Downsampling layer, factor 2\n",
        "\n",
        "    Uses either average pooling (default) or a strided convolution.\n",
        "    \"\"\"\n",
        "    dims: int\n",
        "    out_channels: int = 0\n",
        "    use_conv: bool = False\n",
        "\n",
        "    def setup(self):\n",
        "        if self.use_conv:\n",
        "            assert self.out_channels != 0\n",
        "            self.downsample = ConvND(self.dims, self.out_channels, 3, stride=2, padding=1)\n",
        "        else:\n",
        "            self.downsample = AvgND(self.dims)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.downsample(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WtV_yh4BWxL"
      },
      "source": [
        "### Residual block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hetm2Mql3YoK"
      },
      "source": [
        "class ResBlock(TimestepBlock):\n",
        "    \"\"\"\n",
        "    Residual block with timesteps\n",
        "    \"\"\"\n",
        "    dims: int\n",
        "    in_channels: int\n",
        "    out_channels: int\n",
        "    dropout: float\n",
        "    use_conv: bool = False\n",
        "    up: bool = False\n",
        "    down: bool = False\n",
        "    use_scale_shift_norm: bool = False\n",
        "\n",
        "    def setup(self):\n",
        "        # Initial normalization block\n",
        "        self.in_block = TimestepEmbedSequential((\n",
        "            nn.GroupNorm(epsilon=1e-05),\n",
        "            nn.silu,\n",
        "        ))\n",
        "\n",
        "        # Up/Downsampling block\n",
        "        if self.up:\n",
        "            self.h_upd = Upsample(self.dims) \n",
        "            self.x_upd = Upsample(self.dims)\n",
        "        elif self.down:\n",
        "            self.h_upd = Downsample(self.dims)\n",
        "            self.x_upd = Downsample(self.dims)\n",
        "        else:\n",
        "            self.h_upd = self.x_upd = Identity()\n",
        "\n",
        "        # Input convolution\n",
        "        self.in_conv = ConvND(self.dims, self.out_channels, 3)\n",
        "\n",
        "        # Embedding projection block\n",
        "        self.embed_project = TimestepEmbedSequential((\n",
        "            nn.silu,\n",
        "            nn.Dense(2 * self.out_channels if self.use_scale_shift_norm else self.out_channels)\n",
        "        ))\n",
        "\n",
        "        # Actual layer stack\n",
        "        self.out_norm = nn.GroupNorm(epsilon=1e-05)\n",
        "        self.out_layers = TimestepEmbedSequential((\n",
        "            nn.silu,\n",
        "            nn.Dropout(self.dropout, deterministic=True), # TODO: This should be dynamic, for training. Right now it's a noop.\n",
        "            ConvND(self.dims, self.out_channels, 3) # There was a zero initializer (?) here, it's gone now, sorry. Maybe not important.\n",
        "        ))\n",
        "\n",
        "        # Channel change for skip connection\n",
        "        if self.out_channels == self.in_channels:\n",
        "            self.skip_connection = Identity()\n",
        "        elif self.use_conv:\n",
        "            self.skip_connection = ConvND(self.dims, self.out_channels, 3)\n",
        "        else:\n",
        "            self.skip_connection = ConvND(self.dims, self.out_channels, 1)\n",
        "\n",
        "    def __call__(self, x, emb):\n",
        "        # For residual: Resample x\n",
        "        x_res = self.x_upd(x)\n",
        "\n",
        "        # Run x through input & up/downsample block\n",
        "        x = self.in_block(x)\n",
        "        x = self.h_upd(x)\n",
        "        x = self.in_conv(x)\n",
        "            \n",
        "        # Project embedding and unsqueeze up to match shape of x\n",
        "        emb_out = self.embed_project(emb.reshape(emb.shape[0], -1))\n",
        "        emb_out = emb_out.reshape((emb_out.shape[0],) + tuple([1] * (len(x.shape) - len(emb_out.shape))) + (emb_out.shape[-1],))\n",
        "        \n",
        "        # Apply actual convolution\n",
        "        if self.use_scale_shift_norm:\n",
        "            scale = emb_out[..., :self.out_channels]\n",
        "            shift = emb_out[..., self.out_channels:]\n",
        "            x = self.out_norm(x) * (1 + scale) + shift\n",
        "            x = self.out_layers(x)\n",
        "        else:\n",
        "            x = x + emb_out\n",
        "            x = self.out_norm(x)\n",
        "            x = self.out_layers(x)\n",
        "\n",
        "        # Return residual\n",
        "        return self.skip_connection(x_res) + x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo7iJPGNJVEC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "aa2a628f-af86-4d73-cf29-06bd4bc8d346"
      },
      "source": [
        "# Lets see if it works\n",
        "\"\"\"\n",
        "conv = ResBlock(2, 64, 128, .5, up=True, use_conv=False, use_scale_shift_norm=True)\n",
        "conv_in = jnp.zeros((10, 20, 20, 64))\n",
        "params = conv.init(prng, conv_in, conv_in)\n",
        "conv.apply(params, conv_in, conv_in).shape\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nconv = ResBlock(2, 64, 128, .5, up=True, use_conv=False, use_scale_shift_norm=True)\\nconv_in = jnp.zeros((10, 20, 20, 64))\\nparams = conv.init(prng, conv_in, conv_in)\\nconv.apply(params, conv_in, conv_in).shape\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XwG04UBcH5"
      },
      "source": [
        "### Attention block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN7Eksoq_p3I"
      },
      "source": [
        "class SpatialSelfAttentionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Dot-product attention block for spatial dimensions\n",
        "    \"\"\"\n",
        "    head_channels: int = 64\n",
        "    \n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        # Flatten out spatial channels and norm\n",
        "        batches = x.shape[0]\n",
        "        channels = x.shape[-1]\n",
        "        x_in = x.reshape((batches, -1, channels))\n",
        "        qkv = nn.GroupNorm(epsilon=1e-05)(x_in)\n",
        "\n",
        "        # Convolve to three times the amount of channels and split into query, key and value\n",
        "        qkv = ConvND(1, channels * 3, 1)(qkv)\n",
        "\n",
        "        # Calculate number of heads and split into heads\n",
        "        heads = int(channels / self.head_channels)\n",
        "        qkv = qkv.reshape(batches, -1, heads, self.head_channels * 3)\n",
        "\n",
        "        # Split into query/key/value\n",
        "        query = qkv[:, :, :, 0:self.head_channels] \n",
        "        key = qkv[:, :, :, self.head_channels:self.head_channels*2]\n",
        "        value = qkv[:, :, :, self.head_channels*2:]\n",
        "\n",
        "        # Calculate dot product attention and flatten out\n",
        "        x_out = nn.dot_product_attention(query, key, value, deterministic=True)\n",
        "        x_out = x_out.reshape((batches, -1, channels))\n",
        "\n",
        "        # Project\n",
        "        x_out = ConvND(1, channels, 1)(x_out)\n",
        "\n",
        "        # Resicual and reshape back to original shape\n",
        "        return (x_in + x_out).reshape(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RqCriODF9eFI",
        "outputId": "a2b48575-7fef-4511-f2f8-c2b9c1b1d2f6"
      },
      "source": [
        "# Lets see if it works\n",
        "\"\"\"\n",
        "attention = SpatialSelfAttentionBlock(64)\n",
        "attention_in = jnp.zeros((10, 20, 30, 256))\n",
        "params = attention.init(prng, attention_in)\n",
        "attention.apply(params, attention_in).shape\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nattention = SpatialSelfAttentionBlock(64)\\nattention_in = jnp.zeros((10, 20, 30, 256))\\nparams = attention.init(prng, attention_in)\\nattention.apply(params, attention_in).shape\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwNkwIOzBpgT"
      },
      "source": [
        "# The actual model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYMn4TpX_rMW"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Unet style model with spatial self attention.\n",
        "    Unconditional only, for now.\n",
        "    \"\"\"\n",
        "    dims: int\n",
        "    model_channels: int\n",
        "    channel_mult: int\n",
        "    use_scale_shift_norm: bool\n",
        "    dropout: float\n",
        "    num_head_channels: int\n",
        "    num_res_blocks: int\n",
        "    attention_resolutions: Sequence[int]\n",
        "    out_channels: int\n",
        "\n",
        "    def setup(self):\n",
        "        # Timestep embedding\n",
        "        time_embed_dim = self.model_channels * 4\n",
        "        self.time_embed = TimeEmbed(self.model_channels, 10000, time_embed_dim)\n",
        "\n",
        "        # Initial block for input stack\n",
        "        input_block_out_channels = int(self.channel_mult[0] * self.model_channels)\n",
        "        input_blocks = [TimestepEmbedSequential([ConvND(self.dims, input_block_out_channels, 3, padding = 1)])]\n",
        "\n",
        "        # Loop to create rest of input stack\n",
        "        current_channels = input_ch = int(self.channel_mult[0] * self.model_channels)\n",
        "        input_block_chans = [current_channels]\n",
        "        downsample_fact = 1\n",
        "        for level, mult in enumerate(self.channel_mult):\n",
        "            for _ in range(self.num_res_blocks):\n",
        "                # One res block\n",
        "                layers = [ResBlock(self.dims, current_channels, int(mult * self.model_channels), dropout = self.dropout, use_scale_shift_norm = self.use_scale_shift_norm)]\n",
        "                current_channels = int(mult * self.model_channels)\n",
        "\n",
        "                # One attention block, if requested\n",
        "                if downsample_fact in self.attention_resolutions:\n",
        "                    layers.append(SpatialSelfAttentionBlock(self.num_head_channels))\n",
        "\n",
        "                # Put those in sequence\n",
        "                input_blocks.append(TimestepEmbedSequential(layers))\n",
        "                input_block_chans.append(current_channels)\n",
        "\n",
        "            # Downsample if not the final block\n",
        "            if level != len(self.channel_mult) - 1:\n",
        "                input_blocks.append(ResBlock(self.dims, current_channels, current_channels, dropout = self.dropout, use_scale_shift_norm = self.use_scale_shift_norm, down = True))\n",
        "                input_block_chans.append(current_channels)\n",
        "                downsample_fact *= 2             \n",
        "        self.input_blocks = input_blocks\n",
        "\n",
        "        # Middle block\n",
        "        self.middle_block = TimestepEmbedSequential([\n",
        "            ResBlock(self.dims, current_channels, current_channels, self.dropout, use_scale_shift_norm = self.use_scale_shift_norm),\n",
        "            SpatialSelfAttentionBlock(self.num_head_channels),\n",
        "            ResBlock(self.dims, current_channels, current_channels, self.dropout, use_scale_shift_norm = self.use_scale_shift_norm),\n",
        "        ])\n",
        "\n",
        "        # Output blocks\n",
        "        output_blocks = []\n",
        "        for level, mult in list(enumerate(self.channel_mult))[::-1]:\n",
        "            for i in range(self.num_res_blocks + 1):\n",
        "                # One res block, with skip input from same unet level\n",
        "                skip_channels = input_block_chans.pop()\n",
        "                in_channels = current_channels + skip_channels\n",
        "                layers = [ResBlock(self.dims, in_channels, int(self.model_channels * mult), dropout = self.dropout, use_scale_shift_norm = self.use_scale_shift_norm)]\n",
        "                current_channels = int(self.model_channels * mult)\n",
        "\n",
        "                # One attention block, if requested\n",
        "                if downsample_fact in self.attention_resolutions:\n",
        "                    layers.append(SpatialSelfAttentionBlock(self.num_head_channels))\n",
        "                    \n",
        "                # Upsample, if not the final block\n",
        "                if level != 0 and i == self.num_res_blocks:\n",
        "                    out_ch = current_channels\n",
        "                    layers.append(ResBlock(self.dims, current_channels, current_channels, dropout = self.dropout, use_scale_shift_norm = self.use_scale_shift_norm, up = True))\n",
        "                    downsample_fact //= 2\n",
        "                output_blocks.append(TimestepEmbedSequential(layers))\n",
        "        self.output_blocks = output_blocks\n",
        "\n",
        "        # Final output block\n",
        "        self.out = TimestepEmbedSequential([\n",
        "            nn.GroupNorm(),\n",
        "            nn.silu,\n",
        "            ConvND(self.dims, self.out_channels, 3),\n",
        "        ])\n",
        "\n",
        "    # Left / input side of fotward pass\n",
        "    def forward_in(self, x, t):\n",
        "        emb = self.time_embed(t)\n",
        "\n",
        "        h = x\n",
        "        hs = []\n",
        "        for block in self.input_blocks:\n",
        "            h = block(h, emb)\n",
        "            hs.append(h)\n",
        "\n",
        "        h = self.middle_block(h, emb)\n",
        "        return h, emb, hs\n",
        "        \n",
        "    # Right / output side of forward pass\n",
        "    def forward_out(self, h, emb, hs):\n",
        "        for i in range(len(self.output_blocks)):\n",
        "            h = jnp.concatenate([h, hs[len(self.output_blocks) - i - 1]], axis = -1)\n",
        "            h = self.output_blocks[i](h, emb)\n",
        "        h = self.out(h)\n",
        "        return h\n",
        "\n",
        "    # Full forward pass\n",
        "    def __call__(self, x, t):\n",
        "        emb = self.time_embed(t)\n",
        "\n",
        "        h = x\n",
        "        hs = []\n",
        "        for block in self.input_blocks:\n",
        "            h = block(h, emb)\n",
        "            hs.append(h)\n",
        "\n",
        "        h = self.middle_block(h, emb)\n",
        "\n",
        "        for block in self.output_blocks:\n",
        "            h = jnp.concatenate([h, hs.pop()], axis = -1)\n",
        "            h = block(h, emb)\n",
        "\n",
        "        h = self.out(h)\n",
        "        return h\n",
        "\n",
        "# Helper function for the channel multipliers from the OpenAI guided diffusion model.\n",
        "def get_default_channel_mult(image_size):\n",
        "    channel_mult = None\n",
        "    if image_size == 512:\n",
        "        channel_mult = (0.5, 1, 1, 2, 2, 4, 4)\n",
        "    elif image_size == 256:\n",
        "        channel_mult = (1, 1, 2, 2, 4, 4)\n",
        "    elif image_size == 128:\n",
        "        channel_mult = (1, 1, 2, 3, 4)\n",
        "    elif image_size == 64:\n",
        "        channel_mult = (1, 2, 3, 4)\n",
        "    else:\n",
        "        raise ValueError(f\"unsupported image size: {image_size}\")\n",
        "    return channel_mult\n",
        "\n",
        "if DO_JIT == True:\n",
        "    UNet = nn.jit(UNet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kASxX9OkpPlh"
      },
      "source": [
        "# Lets see if it works, by instantiating parameters for a 256x256 model that matches OpenAIs\n",
        "unet = UNet(\n",
        "    dims = 2,\n",
        "    model_channels = 256,\n",
        "    channel_mult = get_default_channel_mult(256),\n",
        "    use_scale_shift_norm = True,\n",
        "    dropout = 0.0,\n",
        "    num_head_channels = 64,\n",
        "    num_res_blocks = 2,\n",
        "    attention_resolutions = (32, 16, 8),\n",
        "    out_channels = 6\n",
        ")\n",
        "image_in = jnp.zeros((1, 256, 256, 3))\n",
        "embed_in = jnp.zeros((1,))\n",
        "\n",
        "# To instantiate a new model (for training, or loading pytorch params, or renaming parameters after jit-ing parts of the model)\n",
        "#params = unet.init(prng, image_in, embed_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT4-H_7gpT9G",
        "outputId": "7d23717b-97a5-4275-8f91-14517092e0ea"
      },
      "source": [
        "# Or we can just load a pickled set of params\n",
        "if not os.path.exists(\"openai_256x256_diffusion_uncond.pkl\"):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !cp /content/drive/MyDrive/openai_256x256_diffusion_uncond.pkl openai_256x256_diffusion_uncond.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNRnFF0YpUD9"
      },
      "source": [
        "with open(\"openai_256x256_diffusion_uncond.pkl\", \"rb\") as f:\n",
        "    params_load = pickle.load(f)\n",
        "params = jax.device_put(params_load)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvM4QIV_pnpi"
      },
      "source": [
        "# Define split forward passes with the model computation serialized between two cores\n",
        "# This isn't efficient, but at least actually lets the model run like on colab TPUs\n",
        "def forward_pass_1(image_in, embed_in):\n",
        "    return unet.apply(params, image_in, embed_in, method=unet.forward_in)\n",
        "\n",
        "def forward_pass_2(tmp_h, tmp_emb, tmp_hs): \n",
        "    return unet.apply(params, tmp_h, tmp_emb, tmp_hs, method=unet.forward_out)\n",
        "\n",
        "forward_pass_1_jit = jit(forward_pass_1, device = jax.devices()[0])\n",
        "forward_pass_2_jit = jit(forward_pass_2, device = jax.devices()[1])\n",
        "\n",
        "# Define a combined forward pass. Can't jit the whole pass, it does not fit onto a \n",
        "# single TPU core unsharded, and colab TPUs do not support pjit / sharded_jit.\n",
        "def forward_pass(image_in, embed_in):\n",
        "    tmp_h, tmp_emb, tmp_hs = forward_pass_1_jit(image_in, embed_in)\n",
        "    out = forward_pass_2_jit(tmp_h, tmp_emb, tmp_hs)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIGAGPmJqgiU",
        "outputId": "7ea2eee2-164b-495d-f179-9a1cec343791"
      },
      "source": [
        "# And now: Inference!\n",
        "# Doing 1000 steps takes around 5 minutes - not exactly fast\n",
        "image_out = image_in # TODO real input\n",
        "for i in tqdm.tqdm(range(1000)):\n",
        "    out = forward_pass(image_out, embed_in) # TODO timesteps\n",
        "    image_out = out[:, :, :, :3] # Remove extra dimensions\n",
        "image_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [05:01<00:00,  3.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[[-5.38708121e-02,  1.00249201e-02,  9.41987634e-02],\n",
              "               [-1.74444169e-04, -8.01641494e-03,  1.07820466e-01],\n",
              "               [-1.36604235e-02, -1.91797018e-02,  1.29849076e-01],\n",
              "               ...,\n",
              "               [ 1.02168601e-02, -5.85068204e-03,  1.17271289e-01],\n",
              "               [ 2.25835405e-02, -2.53075399e-02,  1.22576877e-01],\n",
              "               [-9.68872607e-02,  1.05745599e-01,  1.29084095e-01]],\n",
              "\n",
              "              [[-8.25234428e-02,  4.09766287e-02, -1.15936864e-02],\n",
              "               [-7.26091713e-02,  3.08041871e-02,  9.44973715e-03],\n",
              "               [-6.91175908e-02,  6.28691912e-02, -1.50876027e-02],\n",
              "               ...,\n",
              "               [-6.09511510e-02,  5.70226051e-02, -5.24333771e-03],\n",
              "               [-2.91892216e-02,  3.03397626e-02, -8.42249207e-03],\n",
              "               [-1.84157342e-01,  2.15163067e-01, -6.60102069e-03]],\n",
              "\n",
              "              [[-6.81292936e-02,  4.67030182e-02, -1.75572205e-02],\n",
              "               [-7.64651150e-02,  6.81040436e-02,  2.87225284e-02],\n",
              "               [-6.47261068e-02,  7.42925256e-02,  1.84111111e-02],\n",
              "               ...,\n",
              "               [-4.69035245e-02,  8.22192132e-02,  5.55748492e-03],\n",
              "               [-3.71295027e-02,  4.83920015e-02,  1.80966146e-02],\n",
              "               [-1.54541552e-01,  2.26987213e-01,  2.25868076e-03]],\n",
              "\n",
              "              ...,\n",
              "\n",
              "              [[-6.00880906e-02,  5.33506535e-02, -2.33976897e-02],\n",
              "               [-6.31432608e-02,  5.65688387e-02,  1.44152399e-02],\n",
              "               [-5.61723635e-02,  6.36363178e-02,  6.28572702e-03],\n",
              "               ...,\n",
              "               [-4.39896248e-02,  7.87548125e-02, -1.09008700e-02],\n",
              "               [-2.30887532e-02,  4.46672440e-02, -6.57037180e-03],\n",
              "               [-1.31619573e-01,  2.10715786e-01, -1.11633781e-02]],\n",
              "\n",
              "              [[-5.81581965e-02,  6.18059263e-02, -4.49808612e-02],\n",
              "               [-4.11083028e-02,  3.97711806e-02, -7.00129196e-04],\n",
              "               [-3.96597646e-02,  6.00595586e-02, -1.78194121e-02],\n",
              "               ...,\n",
              "               [-3.22345644e-02,  7.71389902e-02, -3.91770862e-02],\n",
              "               [-1.18028857e-02,  6.19170070e-02, -3.34446654e-02],\n",
              "               [-1.43298745e-01,  2.01979265e-01, -1.77823044e-02]],\n",
              "\n",
              "              [[-2.28734791e-01,  2.42902577e-01,  1.78895183e-02],\n",
              "               [-2.24744052e-01,  2.13929564e-01,  2.93650590e-02],\n",
              "               [-1.93775892e-01,  1.90868720e-01,  1.96934640e-02],\n",
              "               ...,\n",
              "               [-1.94762766e-01,  2.13435858e-01,  6.21833280e-03],\n",
              "               [-2.17043489e-01,  1.88103765e-01,  4.26566340e-02],\n",
              "               [-1.73802465e-01,  2.61896223e-01, -7.05917031e-02]]]],            dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "olxtXL0BtYoA",
        "outputId": "16f0bad0-8648-4611-e148-e3bd434e9960"
      },
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(image_out[0,:,:,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5429f41b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKCj8zPHZOog"
      },
      "source": [
        "# Appendix A: Loading parameters from pytorch\n",
        "\n",
        "Now that we have a model: Lets load the OpenAI pretrained weights, and see if we match up! This part breaks if you run the JIT because the order seems to not match anymore, so... don't, or do something smarter than just going by order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z35bljjXELF1"
      },
      "source": [
        "# Helper function to build a list of param entries (and print them besides)\n",
        "def traverse_params(params, prefix = \"\", name_prefix = \"\", print_params=False):\n",
        "    param_sum = 0\n",
        "    param_list = []\n",
        "    for key in params.keys():\n",
        "        if isinstance(params[key], flax.core.frozen_dict.FrozenDict) or isinstance(params[key], dict):\n",
        "            if print_params:\n",
        "                print(prefix + key)\n",
        "            param_sum_rec, param_list_rec = traverse_params(params[key], prefix + \"    \", name_prefix + key + \".\", print_params)\n",
        "            param_sum += param_sum_rec\n",
        "            param_list.extend(param_list_rec)\n",
        "        else:\n",
        "            if print_params:\n",
        "                print(prefix + key, params[key].shape)            \n",
        "            param_sum += (params[key].flatten().shape[0])\n",
        "            param_list.append((name_prefix + key, params[key].shape))\n",
        "    return param_sum, param_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1zlTM3f-wD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0195188-aadb-49f1-abab-1db65e435fec"
      },
      "source": [
        "param_sum, param_list = traverse_params(params)\n",
        "print(\"Number of parameters:\", param_sum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 552814086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNhVL7bxFSrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b44031b-e8f8-47c2-b197-17e8ba3d490e"
      },
      "source": [
        "# Import pytorch, download the 256x256 unconditional model, and load the state dictionary\n",
        "import torch as pt\n",
        "!wget https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_diffusion_uncond.pt\n",
        "state_dict = pt.load(\"/content/256x256_diffusion_uncond.pt\", map_location=pt.device(\"cpu\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-31 18:59:57--  https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_diffusion_uncond.pt\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.150.77.132\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.150.77.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2211383297 (2.1G) [application/octet-stream]\n",
            "Saving to: ‘256x256_diffusion_uncond.pt’\n",
            "\n",
            "256x256_diffusion_u 100%[===================>]   2.06G  45.1MB/s    in 47s     \n",
            "\n",
            "2021-07-31 19:00:44 (45.1 MB/s) - ‘256x256_diffusion_uncond.pt’ saved [2211383297/2211383297]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHCTglG5HSMH"
      },
      "source": [
        "# See if shapes match up and build a list of parameters to assign\n",
        "param_dict = {}\n",
        "for (jax_key, jax_shape), torch_key in zip(param_list, state_dict.keys()):\n",
        "    pt_shape = tuple(state_dict[torch_key].shape[::-1])\n",
        "    while len(pt_shape) < len(jax_shape):\n",
        "        pt_shape = (1,) + pt_shape\n",
        "    param_dict[jax_key] = state_dict[torch_key].T.reshape(pt_shape).detach().numpy()\n",
        "    if jax_shape != param_dict[jax_key].shape:\n",
        "        print(\"Shape mismatch:\", jax_key, jax_shape, torch_key, pt_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjQTMPoRHxXz"
      },
      "source": [
        "# Traverse unfrozen version of params and assign according to keys from traverse_params\n",
        "def assign_params(params, param_dict, name_prefix = \"\"):\n",
        "    for key in params.keys():\n",
        "        if isinstance(params[key], dict):\n",
        "            assign_params(params[key], param_dict, name_prefix + key + \".\")\n",
        "        else:\n",
        "            params[key] = param_dict[name_prefix + key]\n",
        "params_load = params.unfreeze()            \n",
        "assign_params(params_load, param_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7N3x3COzsCf"
      },
      "source": [
        "# Now, save the result\n",
        "with open(\"openai_256x256_diffusion_uncond.pkl\", \"wb\") as f:\n",
        "    pickle.dump(params_load, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpDBw8Yx1pWK",
        "outputId": "320de92f-6bbf-4a6a-b1a1-4fd62f330362"
      },
      "source": [
        "# And copy it to somewhere safe\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp openai_256x256_diffusion_uncond.pkl /content/drive/MyDrive/openai_256x256_diffusion_uncond.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoUwzIh3795f"
      },
      "source": [
        "# Appendix B: Rename weights after flax.linen.jit (Maybe don't use that, though)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF6XIAe976-I",
        "outputId": "f8563a1d-4e81-456b-b80b-5c34bd8179d9"
      },
      "source": [
        "# Build a flat dictionary for easy renaming\n",
        "def build_flat_dict(params, prefix = \"\", name_prefix = \"\", print_params=False):\n",
        "    param_sum = 0\n",
        "    param_list = []\n",
        "    for key in params.keys():\n",
        "        if isinstance(params[key], flax.core.frozen_dict.FrozenDict) or isinstance(params[key], dict):\n",
        "            if print_params:\n",
        "                print(prefix + key)\n",
        "            param_sum_rec, param_list_rec = build_flat_dict(params[key], prefix + \"    \", name_prefix + key + \".\", print_params)\n",
        "            param_sum += param_sum_rec\n",
        "            param_list.extend(param_list_rec)\n",
        "        else:\n",
        "            if print_params:\n",
        "                print(prefix + key, params[key].shape)            \n",
        "            param_sum += (params[key].flatten().shape[0])\n",
        "            param_list.append((name_prefix + key, params[key] ))\n",
        "    \n",
        "    if name_prefix == \"\":\n",
        "        param_list = dict(param_list)\n",
        "\n",
        "    return param_sum, param_list\n",
        "\n",
        "param_sum, param_list = traverse_params(params)\n",
        "print(\"Number of parameters:\", param_sum)\n",
        "\n",
        "param_sum_load, param_list_load = build_flat_dict(params_load)\n",
        "print(\"Number of parameters (loaded):\", param_sum_load)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 552814086\n",
            "Number of parameters (loaded): 552814086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32s7KKz5_jKP"
      },
      "source": [
        "# Make sure our renaming gets everything\n",
        "for param in param_list:\n",
        "    param_name = param[0]\n",
        "    param_name_loaded = param_name.replace(\"Jit\", \"\")\n",
        "    if not param_name_loaded in param_list_load:\n",
        "        print(\"MISSING\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ5UXTFYDuxt"
      },
      "source": [
        "# Traverse unfrozen version of params and assign according to keys from traverse_params\n",
        "def assign_params_rename(params, param_dict, name_prefix = \"\"):\n",
        "    for key in params.keys():\n",
        "        if isinstance(params[key], dict):\n",
        "            assign_params_rename(params[key], param_dict, name_prefix + key + \".\")\n",
        "        else:\n",
        "            param_name = name_prefix + key\n",
        "            param_name_loaded = param_name.replace(\"Jit\", \"\")\n",
        "            params[key] = param_dict[param_name_loaded]\n",
        "params_load_renamed = params.unfreeze()            \n",
        "assign_params_rename(params_load_renamed, param_list_load)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiNwV7dTEgZt"
      },
      "source": [
        "# Now, save the result\n",
        "with open(\"openai_256x256_diffusion_uncond_jit.pkl\", \"wb\") as f:\n",
        "    pickle.dump(params_load_renamed, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HaoKhenElCv",
        "outputId": "a3a82d42-e5bd-4367-b35b-c92632f1b4f2"
      },
      "source": [
        "# And copy it to somewhere safe\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp openai_256x256_diffusion_uncond_jit.pkl /content/drive/MyDrive/openai_256x256_diffusion_uncond.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRIC9_keQjzS"
      },
      "source": [
        "# Next up\n",
        "Tomorrow, we continue where we left off: Lets implement the whole unet, maybe train something!"
      ]
    }
  ]
}