{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c590e-0fee-42cd-929d-773ef88fe0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db89bc9-5a0b-491c-947d-c4f0e72f3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ddim.models.unet import UNet\n",
    "from ddim.models.model_utils import get_default_channel_mult, load_params\n",
    "from ddim.diffusion.parameters import linear_beta_schedule, diff_params_from_betas\n",
    "from ddim.diffusion.inference import denoising_loop\n",
    "from ddim.training.steps import get_train_loop\n",
    "from ddim.training.ema import EMA\n",
    "from ddim.training.data import TimestepSampler, ImageDataset, DatasetSampler\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax.experimental.pjit import pjit, PartitionSpec\n",
    "from jax.experimental.maps import mesh\n",
    "import optax\n",
    "\n",
    "import jmp\n",
    "import time\n",
    "\n",
    "import json\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7acd15-5319-4282-899a-764af087d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "config = {\n",
    "    \"seed\": 1337,\n",
    "    \"mesh_shape\": (1, 4, 2),\n",
    "    \"resume\": None,\n",
    "    \"prefix\": \"with_decay\",\n",
    "    \"training\": {\n",
    "        \"learning_rate\": 0.00001,\n",
    "        \"adam_b1\": 0.9,\n",
    "        \"adam_b2\": 0.999,\n",
    "        \"adam_decay\": 0.0001,\n",
    "        \"batch_size\": 1,\n",
    "        \"train_steps_total\": 1000000000,\n",
    "        \"train_steps_per_iter\": 2500,\n",
    "        \"eval_every\": 10000,\n",
    "        \"save_every\": 100000,\n",
    "        \"reduce_lr_steps\": 100000,\n",
    "        \"reduce_lr_thresh\": 0.01,\n",
    "        \"mixed_precision\": True,\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"data_glob\": \"data/portraits/*.jpg\",\n",
    "        \"image_size\": 128,\n",
    "        \"image_base_size\": 512,\n",
    "        \"image_channels\": 3,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"model_channels\": 128,\n",
    "        \"num_head_channels\": 64,\n",
    "        \"use_scale_shift_norm\": True,\n",
    "        \"num_res_blocks\": 2,\n",
    "        \"attention_resolutions\": (32, 16, 8),\n",
    "    },\n",
    "    \"diffusion\": {\n",
    "        \"schedule_steps\": 1000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4f268-04ae-4b1c-a0e1-62eb9e858a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic jax mesh setup\n",
    "prng = jax.random.PRNGKey(config[\"seed\"])\n",
    "devices = np.array(jax.devices()).reshape(config[\"mesh_shape\"])\n",
    "\n",
    "# Precision settings\n",
    "if config[\"training\"][\"mixed_precision\"] == True:\n",
    "    compute_dtype = jnp.bfloat16\n",
    "else:\n",
    "    compute_dtype = jnp.float32\n",
    "    \n",
    "precision_policy = jmp.Policy(\n",
    "    compute_dtype = compute_dtype,\n",
    "    param_dtype = jnp.float32,\n",
    "    output_dtype = jnp.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae57856-b392-415e-97e4-0d302c50adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "prefix = config[\"prefix\"]\n",
    "model = UNet(\n",
    "    dims = 2,\n",
    "    model_channels = config[\"model\"][\"model_channels\"],\n",
    "    channel_mult = get_default_channel_mult(config[\"data\"][\"image_size\"]),\n",
    "    use_scale_shift_norm = config[\"model\"][\"use_scale_shift_norm\"],\n",
    "    dropout = 0.0, # TODO\n",
    "    num_head_channels = config[\"model\"][\"num_head_channels\"],\n",
    "    num_res_blocks = config[\"model\"][\"num_res_blocks\"],\n",
    "    attention_resolutions = config[\"model\"][\"attention_resolutions\"], # TODO seems to be some inconsistency here\n",
    "    out_channels = config[\"data\"][\"image_channels\"],\n",
    "    dtype = precision_policy.compute_dtype,\n",
    "    dtype_out = precision_policy.compute_dtype\n",
    ")\n",
    "\n",
    "if config[\"resume\"] is None:\n",
    "    # Initialize parameters\n",
    "    init_pjit = pjit(model.init, [None, PartitionSpec(\"batch\", \"x\", \"y\"), PartitionSpec(\"batch\")], PartitionSpec(None))\n",
    "    with mesh(devices, ('batch', 'x', 'y')):\n",
    "        params = init_pjit(prng, jnp.zeros((1, config[\"data\"][\"image_size\"], config[\"data\"][\"image_size\"], config[\"data\"][\"image_channels\"])), jnp.zeros((1,)))\n",
    "else:\n",
    "    params = load_params(f\"params_{prefix}_{resume}.pkl\", devices)\n",
    "    # TODO: Restore optimizer state?\n",
    "    \n",
    "params = precision_policy.cast_to_param(params)\n",
    "\n",
    "\"\"\"    \n",
    "param_count = 0\n",
    "for param in jax.tree_util.tree_flatten(params)[0]:\n",
    "    param_count += len(param.flatten())\n",
    "print(f\"param count: {param_count}\")\n",
    "\"\"\"\n",
    "\n",
    "# Initialize diffusion\n",
    "diff_params = diff_params_from_betas(linear_beta_schedule(config[\"diffusion\"][\"schedule_steps\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566e4b8-4d49-48d4-a236-0773ad8d822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pjit the denoising loop\n",
    "def denoising_loop_pjit(params, diff_params, images):\n",
    "    return denoising_loop(model, params, diff_params, images)\n",
    "\n",
    "denoising_loop_pjit = pjit(denoising_loop_pjit, \n",
    "   [\n",
    "       PartitionSpec(None),\n",
    "       PartitionSpec(None),\n",
    "       PartitionSpec(\"batch\", \"x\", \"y\")\n",
    "   ], \n",
    "   PartitionSpec(\"batch\", \"x\", \"y\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c209e5-4061-4c27-8103-69e25567130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "ema = EMA()\n",
    "resize = None\n",
    "if config[\"data\"][\"image_size\"] != config[\"data\"][\"image_base_size\"]:\n",
    "    resize = config[\"data\"][\"image_size\"]\n",
    "dataset = ImageDataset(config[\"data\"][\"data_glob\"], resize = resize)\n",
    "data_sampler = DatasetSampler(dataset, batch_size = config[\"training\"][\"batch_size\"])\n",
    "timestep_sampler = TimestepSampler(config[\"diffusion\"][\"schedule_steps\"], config[\"training\"][\"batch_size\"])\n",
    "\n",
    "opt = optax.chain(\n",
    "    optax.adamw(\n",
    "        b1=config[\"training\"][\"adam_b1\"], \n",
    "        b2=config[\"training\"][\"adam_b2\"], \n",
    "        learning_rate = config[\"training\"][\"learning_rate\"], \n",
    "        eps=1e-8,\n",
    "        weight_decay = config[\"training\"][\"adam_decay\"]\n",
    "    ),\n",
    "    optax.inject_hyperparams(optax.scale)(1.0), # for LR halving\n",
    ")\n",
    "opt_params = opt.init(params)\n",
    "\n",
    "# Build a train loop that runs for 10000 batches\n",
    "train_loop = get_train_loop(\n",
    "    opt, \n",
    "    model, \n",
    "    diff_params, \n",
    "    data_sampler, \n",
    "    timestep_sampler, \n",
    "    ema, \n",
    "    how_many = config[\"training\"][\"train_steps_per_iter\"],\n",
    "    precision_policy = precision_policy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86192cc2-9018-46d8-a1b6-20388277cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard instrumentation\n",
    "writer = SummaryWriter()\n",
    "writer.add_text(\"config\", json.dumps(config, indent=4))\n",
    "\n",
    "# Train\n",
    "loss = None\n",
    "reduce_lr_loss = []\n",
    "start = time.time()\n",
    "start_i = 0\n",
    "if not config[\"resume\"] is None:\n",
    "    start_i = config[\"resume\"] // config[\"training\"][\"train_steps_per_iter\"]\n",
    "    \n",
    "with mesh(devices, ('batch', 'x', 'y')):\n",
    "    for i in range(start_i, config[\"training\"][\"train_steps_total\"] // config[\"training\"][\"train_steps_per_iter\"]):\n",
    "        step = i * config[\"training\"][\"train_steps_per_iter\"]\n",
    "        if step % config[\"training\"][\"eval_every\"] == 0:\n",
    "            # Progress shot\n",
    "            prng_img = jax.random.PRNGKey(random.randint(0, 2**32))\n",
    "            images_in = jax.random.normal(prng_img, (1, config[\"data\"][\"image_size\"], config[\"data\"][\"image_size\"], config[\"data\"][\"image_channels\"]))\n",
    "            timesteps_in = jnp.array([0,], dtype=jnp.int32)\n",
    "            out = denoising_loop_pjit(params, diff_params, images_in.astype(jnp.float32))\n",
    "            image = np.array(((out[0, :, :, :] + 1.0) * 127.5)).astype(np.uint8)\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            \n",
    "            # To tensorboard\n",
    "            writer.add_image(\"out/image\", image.T.transpose(0, 2, 1), i * config[\"training\"][\"train_steps_per_iter\"])\n",
    "        \n",
    "        # Print loss\n",
    "        img_s = (i - start_i) * round((config[\"training\"][\"train_steps_per_iter\"] * config[\"training\"][\"batch_size\"]) / (time.time() - start), 2)\n",
    "        if not loss is None:\n",
    "            print(f\"e: {step}, l: {np.mean(loss)}, img/s: {img_s}\")\n",
    "        \n",
    "            # learning rate halving\n",
    "            reduce_lr_loss.extend(list(np.array(loss).flatten()))\n",
    "            reduce_lr_loss = reduce_lr_loss[-config[\"training\"][\"reduce_lr_steps\"]:]\n",
    "            if step % config[\"training\"][\"reduce_lr_steps\"] == 0:\n",
    "                reduce_lr_loss_past = reduce_lr_loss[:config[\"training\"][\"reduce_lr_steps\"]//2]\n",
    "                reduce_lr_loss_now = reduce_lr_loss[config[\"training\"][\"reduce_lr_steps\"]//2:]\n",
    "                if reduce_lr_loss_now - reduce_lr_loss_past > config[\"training\"][\"reduce_lr_thresh\"]:\n",
    "                    opt_params[1].hyperparams[\"step_size\"] = opt_params[1].hyperparams[\"step_size\"] / 2\n",
    "                writer.add_scalar(\"lr/step_diff\", reduce_lr_loss_now - reduce_lr_loss_past, i * config[\"training\"][\"train_steps_per_iter\"])\n",
    "                \n",
    "        # Tensorboard update\n",
    "        if not loss is None:\n",
    "            writer.add_scalar(\"images_sec\", img_s, step)\n",
    "            writer.add_scalar(\"loss/loop\", np.mean(loss), step)\n",
    "            writer.add_scalar(\"loss/lrstep\", np.mean(reduce_lr_loss), step)\n",
    "            writer.add_scalar(\"lr/scale\", opt_params[1].hyperparams[\"step_size\"], step)\n",
    "            for idx, loss_v in enumerate(list(np.array(loss))):\n",
    "                writer.add_scalar(\"loss/raw\", loss_v, step + idx)\n",
    "            \n",
    "        # Save parameters\n",
    "        if step % config[\"training\"][\"save_every\"] == 0:\n",
    "            with open(f\"params_{prefix}_{step}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(precision_policy.cast_to_output(params), f)\n",
    "            \n",
    "            with open(f\"opt_params_{prefix}_{step}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(precision_policy.cast_to_output(opt_params), f)\n",
    "                \n",
    "        # Run train_steps_per_iter training batches\n",
    "        prng, params, opt_params, loss = train_loop(prng, params, opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46427f40-4f21-456c-81b2-0199371ec333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
