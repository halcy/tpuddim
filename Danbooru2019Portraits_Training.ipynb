{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c590e-0fee-42cd-929d-773ef88fe0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db89bc9-5a0b-491c-947d-c4f0e72f3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ddim.models as models\n",
    "from ddim.models.model_utils import get_default_channel_mult, load_params\n",
    "from ddim.diffusion.parameters import linear_beta_schedule, diff_params_from_betas\n",
    "from ddim.diffusion.inference import denoising_loop\n",
    "from ddim.training.steps import get_train_loop\n",
    "from ddim.training.ema import EMA\n",
    "from ddim.training.data import TimestepSampler, ImageDataset, DatasetSampler\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax.experimental.pjit import pjit, PartitionSpec\n",
    "from jax.experimental.maps import mesh\n",
    "import optax\n",
    "\n",
    "import flax.nn.stochastic as flax_stochastic\n",
    "\n",
    "import jmp\n",
    "import time\n",
    "\n",
    "import json\n",
    "import tensorboardX\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import os\n",
    "import socket\n",
    "from datetime import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66316d8d-ed49-405b-b559-e5c281ab65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../local_data/portraits\"\n",
    "LOG_PREFIX = \"../share_data/runs/active\"\n",
    "OUT_PREFIX = \"../cloud_data/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7acd15-5319-4282-899a-764af087d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "config = {\n",
    "    \"seed\": 1337,\n",
    "    \"mesh_shape\": (1, 4, 2),\n",
    "    \"resume\": None,\n",
    "    \"prefix\": \"128px_unet_wide_deep_drop_highlr_nolrstep_emafix\",\n",
    "    \"log_prefix\": LOG_PREFIX,\n",
    "    \"out_prefix\": OUT_PREFIX,\n",
    "    \"training\": {\n",
    "        \"learning_rate\": 0.00015,\n",
    "        \"adam_b1\": 0.9,\n",
    "        \"adam_b2\": 0.999,\n",
    "        \"adam_decay\": 0.0001,\n",
    "        \"batch_size\": 1,\n",
    "        \"train_steps_total\": 1000000000,\n",
    "        \"train_steps_per_iter\": 2500,\n",
    "        \"eval_every\": 10000,\n",
    "        \"save_every\": 100000,\n",
    "        \"reduce_lr_steps\": 10000000000000,\n",
    "        \"reduce_lr_thresh\": -0.000000001,\n",
    "        \"mixed_precision\": True,\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"data_glob\": os.path.join(DATA_DIR, \"*.jpg\"),\n",
    "        \"image_size\": 128,\n",
    "        \"image_base_size\": 512,\n",
    "        \"image_channels\": 3,\n",
    "    },\n",
    "    \n",
    "    # Mixer config (not recommended, needs work)\n",
    "    #\"model_type\": \"MlpMixer\",\n",
    "    #\"model\": {\n",
    "    #    \"patches\": (16, 16),\n",
    "    #    \"num_blocks\": 23,\n",
    "    #    \"timestep_inject_every\": 3,\n",
    "    #    \"timestep_inject_to\": 18,\n",
    "    #    \"hidden_per_channel\": 384,\n",
    "    #    \"tokens_mlp_dim\": 512,\n",
    "    #    \"channels_mlp_dim\": 3072,\n",
    "    #    \"out_stage_dim_per_channel\": 16,\n",
    "    #    \"out_stage_kernel_dim\": 4,\n",
    "    #},\n",
    "    \n",
    "    # UNet config (like OpenAI)\n",
    "    \"model_type\": \"UNet\",\n",
    "    \"model\": {\n",
    "        \"model_channels\": 128,\n",
    "        \"channel_mult\": (1, 1, 2, 3, 4, 4),\n",
    "        \"num_head_channels\": 64,\n",
    "        \"use_scale_shift_norm\": True,\n",
    "        \"num_res_blocks\": 2,\n",
    "        \"attention_resolutions\": (32, 16, 8, 4),\n",
    "        \"dropout\": 0.1\n",
    "    },\n",
    "    \n",
    "    \"diffusion\": {\n",
    "        \"schedule_steps\": 1000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4f268-04ae-4b1c-a0e1-62eb9e858a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic jax mesh setup\n",
    "prng = jax.random.PRNGKey(config[\"seed\"])\n",
    "devices = np.array(jax.devices()).reshape(config[\"mesh_shape\"])\n",
    "\n",
    "# Precision settings\n",
    "if config[\"training\"][\"mixed_precision\"] == True:\n",
    "    compute_dtype = jnp.bfloat16\n",
    "else:\n",
    "    compute_dtype = jnp.float32\n",
    "    \n",
    "precision_policy = jmp.Policy(\n",
    "    compute_dtype = compute_dtype,\n",
    "    param_dtype = jnp.float32,\n",
    "    output_dtype = jnp.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae57856-b392-415e-97e4-0d302c50adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "prefix = config[\"prefix\"]\n",
    "resume = config[\"resume\"]\n",
    "model_fun = getattr(models, config[\"model_type\"])\n",
    "\n",
    "config[\"model\"][\"out_channels\"] = config[\"data\"][\"image_channels\"]\n",
    "config[\"model\"][\"dtype\"] = precision_policy.compute_dtype\n",
    "config[\"model\"][\"dtype_out\"] = precision_policy.compute_dtype\n",
    "\n",
    "model = model_fun(**config[\"model\"])\n",
    "\n",
    "if config[\"resume\"] is None:\n",
    "    # Initialize parameters\n",
    "    init_pjit = pjit(model.init, [None, PartitionSpec(\"batch\", \"x\", \"y\"), PartitionSpec(\"batch\")], PartitionSpec(None))\n",
    "    with mesh(devices, ('batch', 'x', 'y')):\n",
    "        params = init_pjit(prng, jnp.zeros((1, config[\"data\"][\"image_size\"], config[\"data\"][\"image_size\"], config[\"data\"][\"image_channels\"])), jnp.zeros((1,)))\n",
    "else:\n",
    "    params = load_params(f\"params_{prefix}_{resume}.pkl\", devices)\n",
    "    # TODO: Restore optimizer state?\n",
    "    \n",
    "params = precision_policy.cast_to_param(params)\n",
    "\n",
    "param_count = 0\n",
    "for param in jax.tree_util.tree_flatten(params)[0]:\n",
    "    param_count += len(param.flatten())\n",
    "print(f\"param count: {param_count}\")\n",
    "\n",
    "# Initialize diffusion\n",
    "diff_params = diff_params_from_betas(linear_beta_schedule(config[\"diffusion\"][\"schedule_steps\"]))\n",
    "\n",
    "# Initialize EMA\n",
    "ema_params = copy.deepcopy(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566e4b8-4d49-48d4-a236-0773ad8d822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pjit the denoising loop\n",
    "def denoising_loop_pjit(params, diff_params, images):\n",
    "    return denoising_loop(model, params, diff_params, images)\n",
    "\n",
    "denoising_loop_pjit = pjit(denoising_loop_pjit, \n",
    "   [\n",
    "       PartitionSpec(None),\n",
    "       PartitionSpec(None),\n",
    "       PartitionSpec(\"batch\", \"x\", \"y\")\n",
    "   ], \n",
    "   PartitionSpec(\"batch\", \"x\", \"y\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c209e5-4061-4c27-8103-69e25567130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "ema = EMA()\n",
    "resize = None\n",
    "if config[\"data\"][\"image_size\"] != config[\"data\"][\"image_base_size\"]:\n",
    "    resize = config[\"data\"][\"image_size\"]\n",
    "dataset = ImageDataset(config[\"data\"][\"data_glob\"], resize = resize)\n",
    "data_sampler = DatasetSampler(dataset, batch_size = config[\"training\"][\"batch_size\"])\n",
    "timestep_sampler = TimestepSampler(config[\"diffusion\"][\"schedule_steps\"], config[\"training\"][\"batch_size\"])\n",
    "\n",
    "opt = optax.chain(\n",
    "    optax.adamw(\n",
    "        b1=config[\"training\"][\"adam_b1\"], \n",
    "        b2=config[\"training\"][\"adam_b2\"], \n",
    "        learning_rate = config[\"training\"][\"learning_rate\"], \n",
    "        eps=1e-8,\n",
    "        weight_decay = config[\"training\"][\"adam_decay\"]\n",
    "    ),\n",
    "    optax.inject_hyperparams(optax.scale)(1.0), # for LR halving\n",
    ")\n",
    "opt_params = opt.init(params)\n",
    "opt_params_extra = {} # for lr halving data\n",
    "\n",
    "# Build a train loop that runs for several batches\n",
    "train_loop = get_train_loop(\n",
    "    opt, \n",
    "    model, \n",
    "    diff_params, \n",
    "    data_sampler, \n",
    "    timestep_sampler, \n",
    "    ema, \n",
    "    how_many = config[\"training\"][\"train_steps_per_iter\"],\n",
    "    precision_policy = precision_policy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86192cc2-9018-46d8-a1b6-20388277cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard instrumentation\n",
    "writer = SummaryWriter(logdir = os.path.join(config[\"log_prefix\"], datetime.now().strftime('%b%d_%H-%M-%S') + '_' + socket.gethostname() + \"_\" + config[\"prefix\"]))\n",
    "config_copy = copy.deepcopy(config)\n",
    "config_copy[\"model\"][\"dtype\"] = str(config_copy[\"model\"][\"dtype\"])\n",
    "config_copy[\"model\"][\"dtype_out\"] = str(config_copy[\"model\"][\"dtype_out\"])\n",
    "writer.add_text(\"config\", json.dumps(config_copy, indent=4))\n",
    "\n",
    "# Train\n",
    "loss = None\n",
    "best_loss = jnp.inf\n",
    "reduce_lr_loss = []\n",
    "start = time.time()\n",
    "start_i = 0\n",
    "if not config[\"resume\"] is None:\n",
    "    start_i = config[\"resume\"] // config[\"training\"][\"train_steps_per_iter\"]\n",
    "    \n",
    "with mesh(devices, ('batch', 'x', 'y')):\n",
    "    for i in range(start_i, config[\"training\"][\"train_steps_total\"] // config[\"training\"][\"train_steps_per_iter\"]):\n",
    "        step = i * config[\"training\"][\"train_steps_per_iter\"]\n",
    "        if step % config[\"training\"][\"eval_every\"] == 0:\n",
    "            # Progress shot\n",
    "            prng_img = jax.random.PRNGKey(random.randint(0, 2**32))\n",
    "            images_in = jax.random.normal(prng_img, (1, config[\"data\"][\"image_size\"], config[\"data\"][\"image_size\"], config[\"data\"][\"image_channels\"]))\n",
    "            timesteps_in = jnp.array([0,], dtype=jnp.int32)\n",
    "            out = denoising_loop_pjit(ema_params, diff_params, images_in.astype(jnp.float32))\n",
    "            image = np.array(((out[0, :, :, :] + 1.0) * 127.5)).astype(np.uint8)\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            \n",
    "            # To tensorboard\n",
    "            writer.add_image(\"out/image\", image.T.transpose(0, 2, 1), i * config[\"training\"][\"train_steps_per_iter\"])\n",
    "        \n",
    "        # Print loss\n",
    "        img_s = (i - start_i) * round((config[\"training\"][\"train_steps_per_iter\"] * config[\"training\"][\"batch_size\"]) / (time.time() - start), 2)\n",
    "        if not loss is None:\n",
    "            print(f\"e: {step}, l: {np.mean(loss)}, img/s: {img_s}\")\n",
    "        \n",
    "            # learning rate halving\n",
    "            reduce_lr_loss.extend(list(np.array(loss).flatten()))\n",
    "            reduce_lr_loss = reduce_lr_loss[-config[\"training\"][\"reduce_lr_steps\"]:]\n",
    "            reduce_lr_loss_arr = jnp.array(reduce_lr_loss)\n",
    "            best_new_loss = best_loss\n",
    "            if step != config[\"training\"][\"reduce_lr_steps\"] and step % config[\"training\"][\"reduce_lr_steps\"] == 0:\n",
    "                best_new_loss = reduce_lr_loss_arr.min()\n",
    "                if best_loss - best_new_loss < config[\"training\"][\"reduce_lr_thresh\"]:\n",
    "                    opt_params[1].hyperparams[\"step_size\"] = opt_params[1].hyperparams[\"step_size\"] / 2\n",
    "                writer.add_scalar(\"lr/step_diff\", best_loss - best_new_loss, i * config[\"training\"][\"train_steps_per_iter\"])\n",
    "            best_loss = min(best_loss, best_new_loss)\n",
    "            \n",
    "            opt_params_extra[\"reduce_lr_loss\"] = reduce_lr_loss\n",
    "            opt_params_extra[\"best_loss\"] = best_loss\n",
    "            \n",
    "        # Tensorboard update\n",
    "        if not loss is None:\n",
    "            writer.add_scalar(\"images_sec\", img_s, step)\n",
    "            writer.add_scalar(\"loss/loop\", np.mean(loss), step)\n",
    "            writer.add_scalar(\"loss/lrstep\", np.mean(reduce_lr_loss), step)\n",
    "            writer.add_scalar(\"lr/scale\", opt_params[1].hyperparams[\"step_size\"], step)\n",
    "            for idx, loss_v in enumerate(list(np.array(loss))):\n",
    "                writer.add_scalar(\"loss/raw\", loss_v, step + idx)\n",
    "            \n",
    "        # Save parameters\n",
    "        if step % config[\"training\"][\"save_every\"] == 0:\n",
    "            with open(os.path.join(config[\"out_prefix\"], f\"params_{prefix}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(precision_policy.cast_to_output(params), f)\n",
    "            \n",
    "            with open(os.path.join(config[\"out_prefix\"], f\"params_ema_{prefix}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(precision_policy.cast_to_output(ema_params), f)\n",
    "            \n",
    "            with open(os.path.join(config[\"out_prefix\"], f\"opt_params_{prefix}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump((opt_params_extra, precision_policy.cast_to_output(opt_params)), f)\n",
    "                \n",
    "        # Run train_steps_per_iter training batches\n",
    "        prng, params, ema_params, opt_params, loss = train_loop(prng, params, ema_params, opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57393659-f9a6-45f4-9cb1-1fbf6f217934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
